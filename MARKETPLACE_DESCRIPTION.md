# AI Prompt Security CI

Automatically runs defensive prompt-based security checks (jailbreak, prompt leak, harmful requests) against your AI models during CI/CD.

## Key Features
- CLI + GitHub Action
- Heuristic + LLM-as-judge evaluation
- JSON + Markdown security reports
- DEMO_MODE (no API key needed)
- Sanitized outputs
- maxCalls & fail_on_high flags
- Safe, defensive-only attack library

## Usage
See README.md for installation and configuration instructions.

